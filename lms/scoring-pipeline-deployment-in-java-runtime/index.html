
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>Scoring Pipeline Deployment in Java Runtime</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://storage.googleapis.com/codelab-elements/codelab-elements.css">
  <link rel="stylesheet" href="custom.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  <google-codelab-analytics gaid="UA-49880327-14"></google-codelab-analytics>
  <google-codelab codelab-gaid=""
                  id="scoring-pipeline-deployment-in-java-runtime"
                  title="Scoring Pipeline Deployment in Java Runtime"
                  environment="web"
                  feedback-link="">
    
      <google-codelab-step label="Objective" duration="0">
        <p><strong>Machine Learning Model Deployment</strong> is the process of making your model available in production environments, so they can be used to make predictions for other software systems [1]. Before model deployment, <strong>feature engineering</strong> occurs in the form of preparing data that later on will be used to train a model [2]. Driverless AI <strong>Automatic Machine Learning (AutoML)</strong> combines the best feature engineering and one or more <strong>machine learning models</strong> into a scoring pipeline [3][4]. The <strong>scoring pipeline</strong> is used to score or predict data when given new test data [5]. The <strong>scoring pipeline</strong> comes in two flavors. The first scoring pipeline is a <strong>Model Object, Optimized(MOJO) Scoring Pipeline</strong>, which is a standalone, low-latency model object designed to be easily embeddable in production environments. The second scoring pipeline is a Python Scoring Pipeline, which has a heavy footprint that is all Python and uses the latest libraries of Driverless AI to allow for executing custom scoring recipes[6].</p>
<p>By the end of this tutorial, you will predict the <strong>cooling condition</strong> for a <strong>Hydraulic System Test Rig</strong> by deploying an <strong>embeddable MOJO Scoring Pipeline</strong> into <strong>Java Runtime</strong> using <strong>Java</strong>, <strong>Sparkling Water</strong>, and <strong>PySparkling</strong>. The Hydraulic System Test Rig data comes from the <a href="https://archive.ics.uci.edu/ml/datasets/Condition+monitoring+of+hydraulic+systems#" target="_blank">UCI Machine Learning Repository: Condition Monitoring of Hydraulic Systems Data Set</a>. Hydraulic System Test Rigs are used to test components in Aircraft Equipment, Ministry of Defense, Automotive Applications, and more [7]. This Hydraulic Test Rig is capable of testing a range of flow rates that can achieve different pressures with the ability to heat and cool to simulate testing under different conditions [8]. Testing the pressure, volume flow, and temperature is possible by Hydraulic Test Rig sensors and digital displays. The display panel alerts the user when a criterion is met, displaying either a green or red light[8]. A filter blockage panel indicator is integrated into the panel to ensure the Hydraulic Test Rig&#39;s oil is maintained [8]. The cooling filtration solution is designed to minimize power consumption and expand the life of the Hydraulic Test Rig. We are predicting cooling conditions for Hydraulic System Predictive Maintenance. When the cooling condition is low, our prediction tells us that the cooling of the Hydraulic System is close to total failure and we may need to look into replacing the cooling filtration solution soon.</p>
<p class="image-container"><img alt="cylinder-diagram-1" src="img/a8b156e42a5fb1f0.jpg"></p>
<p>Figure: Hydraulic Test Rig General Cylinder Diagram</p>
<p>The Hydraulic Test Rig consists of a primary and secondary cooling filtration circuit with pumps that deliver flow and pressure to the oil tank. The oil tank box at the bottom. There is a pressure relief control valve for controlling the rising and falling flows. There is a pressure gauge for measuring the pressure.</p>
<h2 is-upgraded>References</h2>
<p>[1] H2O.ai Community AI Glossary: <a href="https://www.h2o.ai/community/glossary/machine-learning-model-deployment-productionization-productionizing-machine-learning-models" target="_blank">Machine Learning Model Deployment</a></p>
<p>[2] H2O.ai Community AI Glossary: <a href="https://www.h2o.ai/community/glossary/feature-engineering-data-transformation" target="_blank">Feature Engineering</a></p>
<p>[3] H2O.ai Community AI Glossary: <a href="https://www.h2o.ai/community/glossary/automatic-machine-learning-automl" target="_blank">Automatic Machine Learning (AutoML)</a></p>
<p>[4] H2O.ai Community AI Glossary: <a href="https://www.h2o.ai/community/glossary/machine-learning-model" target="_blank">Machine Learning Model</a></p>
<p>[5] H2O.ai Community AI Glossary: <a href="https://www.h2o.ai/community/glossary/scoring-pipeline" target="_blank">Scoring Pipeline</a></p>
<p>[6] H2O.ai Community AI Glossary: <a href="https://www.h2o.ai/community/glossary/model-object-optimized-mojo" target="_blank">Model Object, Optimized (MOJO) Scoring Pipeline</a></p>
<p>[7] <a href="https://www.savery.co.uk/systems/test-benches" target="_blank">SAVERY - HYDRAULIC TEST RIGS AND BENCHES</a></p>
<p>[8] <a href="https://www.hydrotechnik.co.uk/flow-and-temperature-hydraulic-test-bed" target="_blank">HYDROTECHNIK - Flow and Temperature Testing Components</a></p>


      </google-codelab-step>
    
      <google-codelab-step label="Prerequisites" duration="0">
        <ul>
<li>Skilled in Java Object Oriented Programming</li>
<li>Driverless AI Environment</li>
<li>Driverless AI License  <ul>
<li>The license is needed to use the <strong>MOJO2 Java Runtime API</strong> to execute the <strong>MOJO Scoring Pipeline</strong> for making predictions</li>
<li><a href="https://www.h2o.ai/try-driverless-ai/" target="_blank">21 day trial license</a></li>
<li>If you need to purchase a Driverless AI license, reach out to our sales team via the <a href="https://www.h2o.ai/company/contact/" target="_blank">contact us form</a></li>
</ul>
</li>
<li>Basic knowledge of Driverless AI or completion of the following tutorials:  <ul>
<li><a href="https://training.h2o.ai/products/tutorial-1a-automatic-machine-learning-introduction-with-driverless-ai" target="_blank">Tutorial 1A: Automatic Machine Learning Introduction with Driverless AI</a></li>
<li><a href="https://training.h2o.ai/products/tutorial-4a-scoring-pipeline-deployment-introduction" target="_blank">Tutorial 4A: Scoring Pipeline Deployment Introduction</a></li>
<li><a href="https://training.h2o.ai/products/tutorial-4b-scoring-pipeline-deployment-templates" target="_blank">Tutorial 4B: Scoring Pipeline Deployment Templates</a></li>
</ul>
</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Task 1: Set Up Environment" duration="0">
        <p>Create Environment Directory Structure</p>
<h2 is-upgraded>Create directory structure for DAI MOJO Java Projects</h2>
<pre><code language="language-bash" class="language-bash"># Create directory where the mojo-pipeline/ folder will be stored
mkdir $HOME/dai-mojo-java/
</code></pre>
<h2 is-upgraded>Set Up Driverless AI MOJO Requirements</h2>
<p>Download MOJO Scoring Pipeline</p>
<p>1. If you have not downloaded the MOJO Scoring Pipeline, go to <a href="https://training.h2o.ai/products/tutorial-4b-scoring-pipeline-deployment-templates" target="_blank">Tutorial 4B: Scoring Pipeline Deployment Templates</a>, then go to <strong>Task 1: Set Up Environment</strong>, then <strong>Download MOJO Scoring Pipeline</strong> to download it. When finished, come back to this tutorial.</p>
<p>2. Move the <strong>mojo.zip</strong> file to <code>dai-mojo-java/</code> folder and then extract it:</p>
<pre><code language="language-bash" class="language-bash">cd $HOME/dai-mojo-java/
mv $HOME/Downloads/mojo.zip .
unzip mojo.zip
</code></pre>
<h2 is-upgraded>Install MOJO2 Java Runtime Dependencies</h2>
<p>3. Download and install Anaconda</p>
<pre><code language="language-bash" class="language-bash"># Download Anaconda
wget https://repo.anaconda.com/archive/Anaconda3-2020.02-Linux-x86_64.sh

# Install Anaconda
bash Anaconda3-2020.02-Linux-x86_64.sh
</code></pre>
<p>4. Create virtual environment and install required packages</p>
<pre><code language="language-bash" class="language-bash"># Install Python 3.6.10
conda create -y -n model-deployment python=3.6
conda activate model-deployment
# Install Java
conda install -y -c conda-forge openjdk=8.0.192

# Install Maven
conda install -y -c conda-forge maven
</code></pre>
<h2 is-upgraded>Set Driverless AI License Key</h2>
<p>5. Set the Driverless AI License Key as a temporary environment variable</p>
<pre><code language="language-bash" class="language-bash"># Set Driverless AI License Key
export DRIVERLESS_AI_LICENSE_KEY=&#34;{license-key}&#34;
</code></pre>
<h2 is-upgraded>Install Sparkling Water</h2>
<p>1. Download and install Spark if not already installed from <a href="https://spark.apache.org/downloads.html" target="_blank">Sparks Download page</a>.</p>
<ul>
<li>Choose Spark release 3.0.0</li>
<li>Choose package type: Pre-built for Hadoop 2.7 and later</li>
</ul>
<p>2. Point SPARK_HOME to the existing installation of Spark and export variable MASTER.</p>
<pre><code language="language-bash" class="language-bash">export SPARK_HOME=&#34;/path/to/spark/installation&#34;
# To launch a local Spark cluster.
export MASTER=&#34;local[*]&#34;
</code></pre>
<p>3. <a href="https://s3.amazonaws.com/h2o-release/sparkling-water/spark-3.0/3.30.1.2-1-3.0/index.html" target="_blank">Download Sparkling Water</a> and then move Sparkling Water to the HOME folder and extract it:</p>
<pre><code language="language-bash" class="language-bash">cd $HOME
mv $HOME/Downloads/sparkling-water-3.30.0.6-1-3.0.zip .
unzip sparkling-water-3.30.0.6-1-3.0.zip
cd sparkling-water-3.30.0.6-1-3.0
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Task 2: Deploy Scoring Pipeline in Java Runtime Concepts" duration="0">
        <h2 is-upgraded>MOJO Scoring Pipeline Files</h2>
<p>After downloading the MOJO scoring pipeline, the <strong>mojo-pipeline</strong> folder comes with many files. The files that are needed to execute the MOJO scoring pipeline include <strong>pipeline.mojo</strong>, <strong>mojo2-runtime.jar</strong>, and <strong>example.csv</strong>. The file that helps with running the pipeline quickly includes <strong>run_example.sh</strong>. The <strong>pipeline.mojo</strong> is the standalone scoring pipeline in MOJO format. This pipeline file contains the packaged feature engineering pipeline and the machine learning model. The <strong>mojo2-runtime.jar</strong> is the MOJO Java API. The <strong>example.csv</strong> contains sample test data.</p>
<h2 is-upgraded>Embedding the MOJO into the Java Runtime</h2>
<p>If you have gone through the earlier scoring pipeline deployment tutorials, you have seen how we deploy the MOJO Scoring Pipeline to a server or serverless instance. Some clients interact with the server to trigger it to execute the MOJO to make predictions. An alternative way to deploy the MOJO Scoring Pipeline is to embed it directly into the Java Runtime Environment where your application is running. So if you are building a Java application using an Integrated Development Environment (IDE) or a text editor, you can import the MOJO Java API. Then use it to load the MOJO, put your test data into a MOJO frame, perform predictions on the data, and return the results.</p>
<h2 is-upgraded>Resources</h2>
<ul>
<li><a href="http://docs.h2o.ai/driverless-ai/1-8-lts/docs/userguide/scoring-mojo-scoring-pipeline.html" target="_blank">Driverless AI MOJO Scoring Pipeline - Java Runtime</a></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Task 3: Batch Scoring" duration="0">
        <p>You will execute the MOJO scoring pipeline in the Java Runtime Environment using Java, PySparkling, and Sparkling Water.</p>
<h2 is-upgraded>Batch Scoring via Run ExecuteMojo Java Example</h2>
<p>You will run the <strong>run_example.sh</strong> script that came with the mojo-pipeline folder. This script requires the mojo file, csv file, and license file. It runs the Java <strong>ExecuteMojo</strong> example program and the mojo makes predictions for a batch of Hydraulic cooling condition.</p>
<p>Since we already have our license file path specified as an environment variable, we will pass in the path to the mojo file and example csv data to the <strong>run_example.sh</strong> and then run it:</p>
<pre><code language="language-bash" class="language-bash">cd $HOME/dai-mojo-java/mojo-pipeline/
bash run_example.sh pipeline.mojo example.csv
</code></pre>
<p class="image-container"><img alt="batch-scoring-via-shell-script-1" src="img/b331df0a4c382b05.jpg"></p>
<p class="image-container"><img alt="batch-scoring-via-shell-script-2" src="img/2feed1483ddf94d2.jpg"></p>
<p>This classification output is the batch scoring done for our Hydraulic System cooling condition. You should receive classification probabilities for cool_cond_y.3, cool_cond_y.20, and cool_cond_y.100. The 3 means the Hydraulic cooler is close to operating at total failure, 20 means it is operating at reduced efficiency and 100 means it is operating at full efficiency.</p>
<p>Similarly, we could execute <strong>run_example.sh</strong> without passing arguments to it by creating temporary environment variables for mojo pipeline file and example csv file paths.</p>
<pre><code language="language-bash" class="language-bash">export MOJO_PIPELINE_FILE=&#34;$HOME/dai-mojo-java/mojo-pipeline/pipeline.mojo&#34;
export EXAMPLE_CSV_FILE=&#34;$HOME/dai-mojo-java/mojo-pipeline/example.csv&#34;
</code></pre>
<p>Then try executing <strong>run_example.sh</strong> and you should get similar results as above.</p>
<pre><code language="language-bash" class="language-bash">bash run_example.sh
</code></pre>
<p>Likewise, we can also execute the <strong>ExecuteMojo</strong> Java application directly as below and get similar results as above:</p>
<pre><code language="language-bash" class="language-bash">java -Dai.h2o.mojos.runtime.license.key=$DRIVERLESS_AI_LICENSE_KEY -cp mojo2-runtime.jar ai.h2o.mojos.ExecuteMojo $MOJO_PIPELINE_FILE $EXAMPLE_CSV_FILE
</code></pre>
<h2 is-upgraded>Batch Scoring via Run PySparkling Program</h2>
<p>Start PySparkling to enter PySpark interactive terminal:</p>
<pre><code language="language-bash" class="language-bash">cd $HOME/sparkling-water-3.30.0.6-1-3.0
./bin/pysparkling --jars $DRIVERLESS_AI_LICENSE_KEY
</code></pre>
<p class="image-container"><img alt="batch-scoring-via-pysparkling-program-1" src="img/4632859fcf0a7821.jpg"></p>
<p>Now that we are in the PySpark interactive terminal, we will import some dependencies:</p>
<pre><code language="language-java" class="language-java"># First, specify the dependency
import os.path
from pysparkling.ml import H2OMOJOPipelineModel,H2OMOJOSettings
</code></pre>
<p>We configure the H2O MOJO Settings to ensure the output columns are named properly and then load the MOJO scoring pipeline:</p>
<pre><code language="language-java" class="language-java"># The &#39;namedMojoOutputColumns&#39; option ensures the output columns are named properly.
settings = H2OMOJOSettings(namedMojoOutputColumns = True)
homePath = os.path.expanduser(&#34;~&#34;)
</code></pre>
<pre><code language="language-java" class="language-java"># Load the pipeline. &#39;settings&#39; is an optional argument.
mojo = H2OMOJOPipelineModel.createFromMojo(homePath + &#34;/dai-mojo-java/mojo-pipeline/pipeline.mojo&#34;, settings)
</code></pre>
<p>Next load the example csv data as Spark&#39;s DataFrame</p>
<pre><code language="language-java" class="language-java"># Load the data as Spark&#39;s Data Frame
dataFrame = spark.read.csv(homePath + &#34;/dai-mojo-java/mojo-pipeline/example.csv&#34;, header=True)
</code></pre>
<p>Finally, we will run batch scoring on the Spark DataFrame using mojo transform and get the scored data for the hydraulic cool condition:</p>
<pre><code language="language-java" class="language-java"># Run the predictions. The predictions contain all the original columns plus the predictions added as new columns
predictions = mojo.transform(dataFrame)

# Get the predictions for desired cols using array with selected col names
predictions.select([mojo.selectPredictionUDF(&#34;cool_cond_y.3&#34;), mojo.selectPredictionUDF(&#34;cool_cond_y.20&#34;), mojo.selectPredictionUDF(&#34;cool_cond_y.100&#34;)]).collect()
</code></pre>
<p class="image-container"><img alt="batch-scoring-via-pysparkling-program-2" src="img/7b9db6c679743fac.jpg"></p>
<pre><code language="language-bash" class="language-bash"># Quit PySparkling
quit()
</code></pre>
<p>The MOJO predicted the Hydraulic System cooling condition for each row within the batch of Hydraulic System test data we passed to it. You should receive classification probabilities for cool_cond_y.3, cool_cond_y.20, and cool_cond_y.100. The 3 means the Hydraulic cooler is close to operating at total failure, 20 means it is operating at reduced efficiency and 100 means it is operating at full efficiency.</p>
<p>So that is how you execute the MOJO scoring pipeline to do batch scoring using PySparkling.</p>
<h2 is-upgraded>Batch Scoring via Run Sparkling Water Program</h2>
<p>Start Sparkling Water to enter Spark interactive terminal:</p>
<pre><code language="language-bash" class="language-bash">cd $HOME/sparkling-water-3.30.0.6-1-3.0
./bin/sparkling-shell --jars $DRIVERLESS_AI_LICENSE_KEY
</code></pre>
<p class="image-container"><img alt="batch-scoring-via-sparkling-water-1" src="img/b46132072db9d5f4.jpg"></p>
<p class="image-container"><img alt="batch-scoring-via-sparkling-water-2" src="img/4fe644ece6cdd609.jpg"></p>
<p>Now that we are in the Spark interactive terminal, we will import some dependencies:</p>
<pre><code language="language-java" class="language-java">// First, specify the dependency
import ai.h2o.sparkling.ml.models.{H2OMOJOPipelineModel,H2OMOJOSettings}
</code></pre>
<p>We configure the H2O MOJO Settings to ensure the output columns are named properly and then load the MOJO scoring pipeline:</p>
<pre><code language="language-java" class="language-java">// The &#39;namedMojoOutputColumns&#39; option ensures the output columns are named properly.
val settings = H2OMOJOSettings(namedMojoOutputColumns = true)

val homePath = sys.env(&#34;HOME&#34;)
</code></pre>
<pre><code language="language-java" class="language-java">// Load the pipeline. &#39;settings&#39; is an optional argument.
val mojo = H2OMOJOPipelineModel.createFromMojo(homePath + &#34;/dai-mojo-java/mojo-pipeline/pipeline.mojo&#34;, settings)
</code></pre>
<p>Next load the example csv data as Spark&#39;s DataFrame</p>
<pre><code language="language-java" class="language-java">// Load the data as Spark&#39;s Data Frame
val dataFrame = spark.read.option(&#34;header&#34;, &#34;true&#34;).csv(homePath + &#34;/dai-mojo-java/mojo-pipeline/example.csv&#34;)
</code></pre>
<p>Finally, we will run batch scoring on the Spark DataFrame using mojo transform and get the scored data for cool efficiency:</p>
<pre><code language="language-java" class="language-java">// Run the predictions. The predictions contain all the original columns plus the predictions
// added as new columns
val predictions = mojo.transform(dataFrame)

# Get the predictions for desired cols sep by comma with selected col names
predictions.select(mojo.selectPredictionUDF(&#34;cool_cond_y.3&#34;), mojo.selectPredictionUDF(&#34;cool_cond_y.20&#34;), mojo.selectPredictionUDF(&#34;cool_cond_y.100&#34;)).show()
</code></pre>
<p class="image-container"><img alt="batch-scoring-via-sparkling-water-3" src="img/2b2cd642e51c37c8.jpg"></p>
<pre><code language="language-bash" class="language-bash"># Quit Sparkling Water
:quit
</code></pre>
<p>The MOJO predicted the Hydraulic System cooling condition for each row within the batch of Hydraulic System test data we passed to it. You should receive classification probabilities for cool_cond_y.3, cool_cond_y.20, and cool_cond_y.100. The 3 means the Hydraulic cooler is close to operating at total failure, 20 means it is operating at reduced efficiency and 100 means it is operating at full efficiency.</p>
<p>So that is how you execute the MOJO scoring pipeline to do batch scoring using Sparkling Water.</p>
<h2 is-upgraded>Resources</h2>
<ul>
<li>H2O.ai Doc: <a href="http://docs.h2o.ai/driverless-ai/1-8-lts/docs/userguide/scoring-mojo-scoring-pipeline.html" target="_blank">Driverless AI MOJO Scoring Pipeline - Java Runtime</a></li>
<li>Stackoverflow: <a href="https://stackoverflow.com/questions/46813283/select-columns-in-pyspark-dataframe" target="_blank">Select columns in Pyspark Dataframe</a></li>
<li>ai.h2o javadoc for PySparkling: <a href="https://javadoc.io/doc/ai.h2o/sparkling-water-scoring_2.11/latest/index.html#package" target="_blank">sparkling-water-scoring_2.11</a></li>
<li>H2O.ai Doc: <a href="http://docs.h2o.ai/driverless-ai/1-8-lts/docs/userguide/scoring-mojo-scoring-pipeline.html" target="_blank">Driverless AI MOJO Scoring Pipeline - Java Runtime</a></li>
<li>Stackoverflow: <a href="https://stackoverflow.com/questions/51689460/select-specific-columns-from-spark-dataframe" target="_blank">Select Specific Columns from Spark DataFrame</a></li>
<li>ai.h2o javadoc for Sparkling Water: <a href="https://javadoc.io/doc/ai.h2o/sparkling-water-scoring_2.11/latest/index.html#package" target="_blank">sparkling-water-scoring_2.11</a></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Task 4: Interactive Scoring" duration="0">
        <p>The mojo can also predict a Hydraulic System cooling condition for each individual Hydraulic System row of test data. You will build a Java, PySparkling, and Sparkling Water program to execute the mojo to do interactive scoring on individual Hydraulic System rows.</p>
<h2 is-upgraded>Interactive Scoring via Run Custom Java Program</h2>
<p>Create a <strong>MojoDeployment</strong> folder and go into it:</p>
<pre><code language="language-bash" class="language-bash">cd $HOME/dai-mojo-java/apps/
mkdir MojoDeployment
cd MojoDeployment
</code></pre>
<p>Make sure the java runtime file mojo2-runtime.jar and pipeline.mojo is located in this folder:</p>
<pre><code language="language-bash" class="language-bash">cp $HOME/dai-mojo-java/mojo-pipeline/mojo2-runtime.jar .
cp $HOME/dai-mojo-java/mojo-pipeline/pipeline.mojo .
</code></pre>
<p>In the H2O documentation <a href="http://docs.h2o.ai/driverless-ai/1-8-lts/docs/userguide/scoring-mojo-scoring-pipeline.html" target="_blank">Driverless AI MOJO Scoring Pipeline - Java Runtime</a>, they give us a Java code example to predict a CAPSULE value from an individual row of data, we need to modify this code for our Hydraulic System data. Create a Java file called <strong>ExecuteDaiMojo.java</strong>.</p>
<p>Based on our Hydraulic System <strong>example.csv</strong> data, we can take the header row and a row of data to replace the data in rowBuilder in the Java code example. So, the Java code example becomes:</p>
<pre><code language="language-java" class="language-java">import java.io.IOException;
import ai.h2o.mojos.runtime.MojoPipeline;
import ai.h2o.mojos.runtime.frame.MojoFrame;
import ai.h2o.mojos.runtime.frame.MojoFrameBuilder;
import ai.h2o.mojos.runtime.frame.MojoRowBuilder;
import ai.h2o.mojos.runtime.lic.LicenseException;
import ai.h2o.mojos.runtime.utils.CsvWritingBatchHandler;
import com.opencsv.CSVWriter;
import java.io.BufferedWriter;
import java.io.OutputStreamWriter;
import java.io.Writer;
public class ExecuteDaiMojo {
 public static void main(String[] args) throws IOException, LicenseException {
    // Load model and csv
   String homePath = System.getProperty(&#34;user.home&#34;);
   final MojoPipeline model = MojoPipeline.loadFrom(homePath + &#34;/dai-mojo-java/mojo-pipeline/pipeline.mojo&#34;);
   // Get and fill the input columns
    final MojoFrameBuilder frameBuilder = model.getInputFrameBuilder();
    final MojoRowBuilder rowBuilder = frameBuilder.getMojoRowBuilder();
   rowBuilder.setValue(&#34;psa_bar&#34;, &#34;155.6405792236328&#34;);
   rowBuilder.setValue(&#34;psb_bar&#34;, &#34;104.91106414794922&#34;);
   rowBuilder.setValue(&#34;psc_bar&#34;, &#34;0.862698495388031&#34;);
   rowBuilder.setValue(&#34;psd_bar&#34;, &#34;0.00021100000594742596&#34;);
   rowBuilder.setValue(&#34;pse_bar&#34;, &#34;8.370246887207031&#34;);
   rowBuilder.setValue(&#34;psf_bar&#34;, &#34;8.327606201171875&#34;);
   rowBuilder.setValue(&#34;motor_power_watt&#34;, &#34;2161.530029296875&#34;);
   rowBuilder.setValue(&#34;fsa_vol_flow&#34;, &#34;2.0297765731811523&#34;);
   rowBuilder.setValue(&#34;fsb_vol_flow&#34;, &#34;8.869428634643555&#34;);
   rowBuilder.setValue(&#34;tsa_temp&#34;, &#34;35.32681655883789&#34;);
   rowBuilder.setValue(&#34;tsb_temp&#34;, &#34;40.87480163574219&#34;);
   rowBuilder.setValue(&#34;tsc_temp&#34;, &#34;38.30345153808594&#34;);
   rowBuilder.setValue(&#34;tsd_temp&#34;, &#34;30.47344970703125&#34;);
   rowBuilder.setValue(&#34;pump_eff&#34;, &#34;2367.347900390625&#34;);
   rowBuilder.setValue(&#34;vs_vib&#34;, &#34;0.5243666768074036&#34;);
   rowBuilder.setValue(&#34;cool_eff_pct&#34;, &#34;27.3796&#34;);
   rowBuilder.setValue(&#34;cool_pwr_kw&#34;, &#34;1.3104666471481323&#34;);
   rowBuilder.setValue(&#34;eff_fact_pct&#34;, &#34;29.127466201782227&#34;);
   frameBuilder.addRow(rowBuilder);
  // Create a frame which can be transformed by MOJO pipeline
  final MojoFrame iframe = frameBuilder.toMojoFrame();
  // Transform input frame by MOJO pipeline
  final MojoFrame oframe = model.transform(iframe);
  // `MojoFrame.debug()` can be used to view the contents of a Frame
  // oframe.debug();
  // Output prediction as CSV
  final Writer writer = new BufferedWriter(new OutputStreamWriter(System.out));
  final CSVWriter csvWriter = new CSVWriter(writer, &#39;\n&#39;, &#39;&#34;&#39;, &#39;&#34;&#39;);
  CsvWritingBatchHandler.csvWriteFrame(csvWriter, oframe, true);
 }
}
</code></pre>
<p>Now we have our ExecuteDaiMojo.java code, so let&#39;s compile it:</p>
<pre><code language="language-bash" class="language-bash">javac -cp mojo2-runtime.jar -J-Xms2g ExecuteDaiMojo.java
</code></pre>
<p>ExecuteDaiMojo.class is generated. Run this Java program to execute the MOJO:</p>
<pre><code language="language-bash" class="language-bash">java -Dai.h2o.mojos.runtime.license.file=$DRIVERLESS_AI_LICENSE_KEY -cp .:mojo2-runtime.jar ExecuteDaiMojo
</code></pre>
<p><strong>Note</strong>: Windows users run</p>
<pre><code language="language-bash" class="language-bash">java -Dai.h2o.mojos.runtime.license.file=license.sig -cp .;mojo2-runtime.jar ExecuteDaiMojo
</code></pre>
<p class="image-container"><img alt="interactive-scoring-via-custom-java-program-1" src="img/fa00e6b6e38d36a1.jpg"></p>
<p><em>Note:</em></p>
<ul>
<li>cool_cond_y.3 =  0.28380922973155975</li>
<li>cool_cond_y.20 = 0.14792289088169733</li>
<li>cool_cond_y.100 = 0.5682678818702698</li>
</ul>
<p>The MOJO predicted the cooling condition for the individual row of Hydraulic System test data we passed to it. You should receive classification probabilities for cool_cond_y.3, cool_cond_y.20, and cool_cond_y.100. The 3 means the Hydraulic cooler is close to operating at total failure, 20 means it is operating at reduced efficiency and 100 means it is operating at full efficiency.</p>
<p>So that is how you execute the MOJO scoring pipeline to do interactive scoring using Java directly.</p>
<h2 is-upgraded>Resources</h2>
<ul>
<li>H2O.ai Doc: <a href="http://docs.h2o.ai/driverless-ai/1-8-lts/docs/userguide/scoring-mojo-scoring-pipeline.html" target="_blank">Driverless AI MOJO Scoring Pipeline - Java Runtime</a></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Task 5: Challenge" duration="0">
        <h2 is-upgraded>Execute Scoring Pipeline for a New Dataset</h2>
<p>There are various challenges one could do, you could do something that helps you in your daily life or job. Maybe there is a dataset you are working with, you could reproduce the steps we did above, but for your dataset, build a new experiment and execute your MOJO scoring pipeline to do batch scoring or interactive scoring.</p>
<h2 is-upgraded>Embed Scoring Pipeline into Existing Program</h2>
<p>Another challenge could be to use the existing MOJO scoring pipeline we executed and instead of using the examples we shared above, integrate the scoring pipeline into an existing Java, Python or Scala program.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Next Steps" duration="0">
        <ul>
<li><a href="https://training.h2o.ai/products/tutorial-4d-scoring-pipeline-execution-runtime-in-c" target="_blank">Tutorial 4D: Scoring Pipeline Deployment in C++ Runtime</a></li>
<li><a href="https://training.h2o.ai/products/tutorial-4e-scoring-pipeline-deployment-in-python-runtime" target="_blank">Tutorial 4E: Scoring Pipeline Deployment in Python Runtime</a></li>
<li><a href="https://training.h2o.ai/products/tutorial-4f-scoring-pipeline-deployment-to-apache-nifi" target="_blank">Tutorial 4F: Scoring Pipeline Deployment to Apache NiFi</a></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Appendix A: Glossary" duration="0">
        <p>Refer to <a href="https://www.h2o.ai/community/top-links/ai-glossary-search" target="_blank">H2O.ai AI Glossary</a> for relevant Model Deployment Terms</p>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://storage.googleapis.com/codelab-elements/native-shim.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/custom-elements.min.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/prettify.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/codelab-elements.js"></script>
  <script src="//support.google.com/inapp/api.js"></script>

</body>
</html>
